{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras_hub\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show GPU device(s):\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets and model directories\n",
    "cache_dir = os.environ['HOME']\n",
    "imdb_path = 'imdb.npz'\n",
    "imdb_word_index_path = os.path.join(cache_dir, '.keras', 'datasets', 'imdb_word_index.json')\n",
    "model_path = os.path.join(cache_dir, '.kagglehub/models/keras/bert/keras/bert_medium_en_uncased/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"best\" trained weights directory\n",
    "weights_dir = 'weights'\n",
    "os.makedirs(weights_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset, consisting of 25,000 movie reviews from IMDB, \n",
    "# labeled by sentiment (positive/negative)\n",
    "# get features and labels\n",
    "# Use the default parameters to keras.datasets.imdb.load_data\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
    "    path=imdb_path,\n",
    "    num_words=None,\n",
    "    skip_top=0,\n",
    "    maxlen=None,\n",
    "    seed=113,\n",
    "    start_char=start_char,\n",
    "    oov_char=oov_char,\n",
    "    index_from=index_from,\n",
    ")\n",
    "\n",
    "# split test into validation and test 50/50\n",
    "x_val = x_test[:(x_test.shape[0]//2)]\n",
    "y_val = y_test[:(y_test.shape[0]//2)]\n",
    "x_test = x_test[(x_test.shape[0]//2):]\n",
    "y_test = y_test[(y_test.shape[0]//2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunkate and pad short sequences. oov_char is 2\n",
    "maxlen = 512\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen, \n",
    "                                                     padding='post', \n",
    "                                                     truncating='post', \n",
    "                                                     value=oov_char)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, \n",
    "                                                   maxlen=maxlen, \n",
    "                                                   padding='post', \n",
    "                                                   truncating='post', \n",
    "                                                   value=oov_char)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, \n",
    "                                                    maxlen=maxlen, \n",
    "                                                    padding='post', \n",
    "                                                    truncating='post', \n",
    "                                                    value=oov_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary with word index mapping\n",
    "with open(imdb_word_index_path) as f:\n",
    "    word_index = json.load(f)\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "# And add `index_from` to indices to sync with `x_train`\n",
    "inverted_word_index = dict(\n",
    "    (i + index_from, word) for (word, i) in word_index.items()\n",
    ")\n",
    "# Update `inverted_word_index` to include `start_char` and `oov_char`\n",
    "inverted_word_index[start_char] = \"[START]\"\n",
    "inverted_word_index[oov_char] = \"[OOV]\"\n",
    "\n",
    "# decode the sequences:\n",
    "x_train_decoded = [\" \".join(inverted_word_index[i] for i in x) for x in x_train]\n",
    "x_val_decoded = [\" \".join(inverted_word_index[i] for i in x) for x in x_val]\n",
    "x_test_decoded = [\" \".join(inverted_word_index[i] for i in x) for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained classifier.\n",
    "classifier = keras_hub.models.BertClassifier.from_preset(\n",
    "    model_path,\n",
    "    num_classes=2,  # binary classification (positive/negative)\n",
    ")\n",
    "\n",
    "# Re-compile (e.g., with a new learning rate).\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(5e-6),  # 5e-5\n",
    "    jit_compile=True,\n",
    ")\n",
    "\n",
    "# Access backbone programmatically (e.g., to change `trainable`).\n",
    "classifier.backbone.trainable = True  # enable/disable fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show backbone summary\n",
    "classifier.backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model summary\n",
    "keras.utils.plot_model(classifier.backbone, show_shapes=True, \n",
    "                       show_layer_activations=True, \n",
    "                       show_trainable=True, dpi=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show classifier summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model summary\n",
    "keras.utils.plot_model(classifier, show_shapes=True, \n",
    "                       show_layer_activations=True, \n",
    "                       show_trainable=True, dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier, with early stopping and weights saving\n",
    "# earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', mode='max', patience=3)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(weights_dir, 'bert_base_en_classifier_imdb_finetuning.best.keras'),\n",
    "    # monitor='val_loss',  # val_sparse_categorical_accuracy\n",
    "    # mode='min',  # max\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = classifier.fit(x=x_train_decoded, y=y_train, \n",
    "                         batch_size=128, epochs=100, \n",
    "                         validation_data=(x_val_decoded, y_val), \n",
    "                         callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the last update\n",
    "classifier.save(os.path.join(weights_dir, 'bert_base_en_classifier_imdb_finetuning.last.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training history (loss, accuracy)\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(6, 6))\n",
    "axes[0].semilogy(history.history['loss'])\n",
    "axes[0].semilogy(history.history['val_loss'])\n",
    "axes[0].set_ylabel('loss')\n",
    "axes[0].legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "axes[1].plot(history.history['sparse_categorical_accuracy'])\n",
    "axes[1].plot(history.history['val_sparse_categorical_accuracy'])\n",
    "axes[1].set_ylabel('sparse_categorical_accuracy')\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].legend(['train', 'val'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional; reload best/last model for predictions\n",
    "classifier = keras.models.load_model(\n",
    "    filepath=os.path.join(weights_dir, \n",
    "                          'bert_base_en_classifier_imdb_finetuning.best.keras'),\n",
    "                        custom_objects=None, compile=False, safe_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "pred_train = classifier.predict(x_train_decoded)\n",
    "pred_val = classifier.predict(x_val_decoded)\n",
    "pred_test = classifier.predict(x_test_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to labels (no need to convert logits to probabilities)\n",
    "pred_train_labels = np.argmax(pred_train, axis=1)\n",
    "pred_val_labels = np.argmax(pred_val, axis=1)\n",
    "pred_test_labels = np.argmax(pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted \"probabilities\" for positive class\n",
    "pred_prob_train = keras.ops.softmax(pred_train)[:, 1]\n",
    "pred_prob_val = keras.ops.softmax(pred_val)[:, 1]\n",
    "pred_prob_test = keras.ops.softmax(pred_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curves\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for y, y_prob, label in zip([y_train, y_val, y_test], \n",
    "                            [pred_prob_train, pred_prob_val, pred_prob_test], \n",
    "                            ['train', 'val', 'test']):\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(y, y_prob)\n",
    "    ax.plot(fpr, tpr, label=label)\n",
    "ax.plot([0, 1], [0, 1], 'k:', label='_nolegend_')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall curves\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for y, y_prob, label in zip([y_train, y_val, y_test], \n",
    "                            [pred_prob_train, pred_prob_val, pred_prob_test], \n",
    "                            ['train', 'val', 'test']):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(y, y_prob)\n",
    "    ax.plot(recall, precision, label=label)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some common metrics\n",
    "metrics = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'f1', \n",
    "                                'ROCAUC', 'AP', 'bal_accuracy', \n",
    "                                'MCC', 'TP', 'FP', 'FN', 'TN'])\n",
    "skm = sklearn.metrics\n",
    "\n",
    "for y, pred, prob, label in zip([y_train, y_val, y_test], \n",
    "                          [pred_train_labels, pred_val_labels, pred_test_labels],\n",
    "                          [pred_prob_train, pred_prob_val, pred_prob_test],\n",
    "                          ['train', 'val', 'test']):\n",
    "    metrics.loc[label, 'accuracy'] = skm.accuracy_score(y, pred)\n",
    "    metrics.loc[label, 'precision'] = skm.precision_score(y, pred)\n",
    "    metrics.loc[label, 'recall'] = skm.recall_score(y, pred)\n",
    "    metrics.loc[label, 'f1'] = skm.f1_score(y, pred)\n",
    "    metrics.loc[label, 'ROCAUC'] = skm.roc_auc_score(y, prob)\n",
    "    metrics.loc[label, 'AP'] = skm.average_precision_score(y, prob)\n",
    "    metrics.loc[label, 'bal_accuracy'] = skm.balanced_accuracy_score(y, pred)\n",
    "    metrics.loc[label, 'MCC'] = skm.matthews_corrcoef(y, pred)\n",
    "    (metrics.loc[label, 'TP'],\n",
    "     metrics.loc[label, 'FP'],\n",
    "     metrics.loc[label, 'FN'],\n",
    "     metrics.loc[label, 'TN']) = skm.confusion_matrix(y, pred).ravel()\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
