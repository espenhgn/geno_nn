{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_hub\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show GPU device(s):\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets and model directories\n",
    "cache_dir = os.getcwd()\n",
    "imdb_path = 'imdb.npz'\n",
    "imdb_word_index_path = os.path.join(cache_dir, 'keras', 'datasets', 'imdb_word_index.json')\n",
    "model_path = os.path.join(cache_dir, 'kagglehub/models/keras/bert/keras/bert_tiny_en_uncased/3')\n",
    "# model_path = os.path.join(cache_dir, 'kagglehub/models/keras/bert/keras/bert_base_en_uncased/3')\n",
    "# model_path = os.path.join(cache_dir, 'kagglehub/models/keras/bert/keras/bert_base_en/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset, consisting of 25,000 movie reviews from IMDB, labeled by sentiment (positive/negative)\n",
    "# get features and labels\n",
    "# Use the default parameters to keras.datasets.imdb.load_data\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
    "    path=imdb_path,\n",
    "    cache_dir=cache_dir,\n",
    "    num_words=None,\n",
    "    skip_top=0,\n",
    "    maxlen=None,\n",
    "    seed=113,\n",
    "    start_char=start_char,\n",
    "    oov_char=oov_char,\n",
    "    index_from=index_from,\n",
    ")\n",
    "\n",
    "# split test into validation and test 50/50\n",
    "x_val = x_test[:(x_test.shape[0]//2)]\n",
    "y_val = y_test[:(y_test.shape[0]//2)]\n",
    "x_test = x_test[(x_test.shape[0]//2):]\n",
    "y_test = y_test[(y_test.shape[0]//2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunkate and pad short sequences. oov_char is 2\n",
    "maxlen = 256\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen, padding='post', truncating='post', value=oov_char)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen, padding='post', truncating='post', value=oov_char)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen, padding='post', truncating='post', value=oov_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary with word index mapping\n",
    "with open(imdb_word_index_path) as f:\n",
    "    word_index = json.load(f)\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "# And add `index_from` to indices to sync with `x_train`\n",
    "inverted_word_index = dict(\n",
    "    (i + index_from, word) for (word, i) in word_index.items()\n",
    ")\n",
    "# Update `inverted_word_index` to include `start_char` and `oov_char`\n",
    "inverted_word_index[start_char] = \"[START]\"\n",
    "inverted_word_index[oov_char] = \"[OOV]\"\n",
    "\n",
    "# decode the sequences:\n",
    "x_train_decoded = [\" \".join(inverted_word_index[i] for i in x) for x in x_train]\n",
    "x_val_decoded = [\" \".join(inverted_word_index[i] for i in x) for x in x_val]\n",
    "x_test_decoded = [\" \".join(inverted_word_index[i] for i in x) for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained classifier.\n",
    "classifier = keras_hub.models.BertClassifier.from_preset(\n",
    "    model_path,\n",
    "    num_classes=2,  # binary classification (positive/negative)\n",
    ")\n",
    "\n",
    "# Re-compile (e.g., with a new learning rate).\n",
    "'''\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(5e-5),\n",
    "    jit_compile=True,\n",
    ")\n",
    "'''\n",
    "\n",
    "# Access backbone programmatically (e.g., to change `trainable`).\n",
    "classifier.backbone.trainable = False  # enable/disable fine-tuning. Enabling is slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show backbone summary\n",
    "classifier.backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show classifier summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier.\n",
    "history = classifier.fit(x=x_train_decoded, y=y_train, batch_size=64, epochs=10, validation_data=(x_val_decoded, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training history\n",
    "plt.figure()\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "pred_train = classifier.predict(x_train_decoded)\n",
    "pred_val = classifier.predict(x_val_decoded)\n",
    "pred_test = classifier.predict(x_test_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to labels (no need to convert logits to probabilities)\n",
    "pred_train_labels = np.argmax(pred_train, axis=1)\n",
    "pred_val_labels = np.argmax(pred_val, axis=1)\n",
    "pred_test_labels = np.argmax(pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted \"probabilities\" for positive class\n",
    "pred_prob_train = keras.ops.softmax(pred_train)[:, 1]\n",
    "pred_prob_val = keras.ops.softmax(pred_val)[:, 1]\n",
    "pred_prob_test = keras.ops.softmax(pred_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_val.shape, pred_val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curves\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for y, y_prob, label in zip([y_train, y_val, y_test], \n",
    "                            [pred_prob_train, pred_prob_val, pred_prob_test], \n",
    "                            ['train', 'val', 'test']):\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(y, y_prob)\n",
    "    ax.plot(fpr, tpr, label=label)\n",
    "ax.plot([0, 1], [0, 1], 'k:', label='_nolegend_')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall curves\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for y, y_prob, label in zip([y_train, y_val, y_test], \n",
    "                            [pred_prob_train, pred_prob_val, pred_prob_test], \n",
    "                            ['train', 'val', 'test']):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(y, y_prob)\n",
    "    ax.plot(recall, precision, label=label)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some common metrics\n",
    "metrics = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'f1', 'ROCAUC', 'AP', 'bal_accuracy', 'MCC', 'TP', 'FP', 'FN', 'TN'])\n",
    "skm = sklearn.metrics\n",
    "\n",
    "for y, pred, prob, label in zip([y_train, y_val, y_test], \n",
    "                          [pred_train_labels, pred_val_labels, pred_test_labels],\n",
    "                          [pred_prob_train, pred_prob_val, pred_prob_test],\n",
    "                          ['train', 'val', 'test']):\n",
    "    metrics.loc[label, 'accuracy'] = skm.accuracy_score(y, pred)\n",
    "    metrics.loc[label, 'precision'] = skm.precision_score(y, pred)\n",
    "    metrics.loc[label, 'recall'] = skm.recall_score(y, pred)\n",
    "    metrics.loc[label, 'f1'] = skm.f1_score(y, pred)\n",
    "    metrics.loc[label, 'ROCAUC'] = skm.roc_auc_score(y, prob)\n",
    "    metrics.loc[label, 'AP'] = skm.average_precision_score(y, prob)\n",
    "    metrics.loc[label, 'bal_accuracy'] = skm.balanced_accuracy_score(y, pred)\n",
    "    metrics.loc[label, 'MCC'] = skm.matthews_corrcoef(y, pred)\n",
    "    (metrics.loc[label, 'TP'],\n",
    "     metrics.loc[label, 'FP'],\n",
    "     metrics.loc[label, 'FN'],\n",
    "     metrics.loc[label, 'TN']) = skm.confusion_matrix(y, pred).ravel()\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geno_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
